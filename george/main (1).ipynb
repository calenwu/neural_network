{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "from keras import metrics\n",
    "from keras import Model\n",
    "from keras.applications import efficientnet_v2\n",
    "from tensorflow.python.data.ops.dataset_ops import TensorSliceDataset\n",
    "from PIL import Image\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "result = open('../sample.txt', 'r')\n",
    "train_triplet = open('../train_triplets.txt', 'r')\n",
    "test_triplet = open('../test_triplets.txt', 'r')\n",
    "result_lines = result.readlines()\n",
    "train_triplet_lines = train_triplet.readlines()\n",
    "test_triplet_lines = test_triplet.readlines()\n",
    "result.close()\n",
    "train_triplet.close()\n",
    "test_triplet.close()\n",
    "images_dir = '../food_240/'\n",
    "\n",
    "\n",
    "target_shape = (224, 224)\n",
    "\n",
    "\n",
    "print('Num GPUs Available: ', len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "\n",
    "class DistanceLayer(layers.Layer):\n",
    "\t\"\"\"\n",
    "\tThis layer is responsible for computing the distance between the anchor\n",
    "\tembedding and the positive embedding, and the anchor embedding and the\n",
    "\tnegative embedding.\n",
    "\t\"\"\"\n",
    "\tdef __init__(self, **kwargs):\n",
    "\t\tsuper().__init__(**kwargs)\n",
    "\n",
    "\tdef call(self, anchor, positive, negative):\n",
    "\t\tap_distance = tf.reduce_sum(tf.square(anchor - positive), -1)\n",
    "\t\tan_distance = tf.reduce_sum(tf.square(anchor - negative), -1)\n",
    "\t\treturn (ap_distance, an_distance)\n",
    "\n",
    "\n",
    "class SiameseModel(Model):\n",
    "\t\"\"\"\n",
    "\tThe Siamese Network model with a custom training and testing loops.\n",
    "\tComputes the triplet loss using the three embeddings produced by the\n",
    "\tSiamese Network.\n",
    "\n",
    "\tThe triplet loss is defined as:\n",
    "\t\tL(A, P, N) = max(‖f(A) - f(P)‖² - ‖f(A) - f(N)‖² + margin, 0)\n",
    "\t\"\"\"\n",
    "\tdef __init__(self, siamese_network, margin=0.5):\n",
    "\t\tsuper(SiameseModel, self).__init__()\n",
    "\t\tself.siamese_network = siamese_network\n",
    "\t\tself.margin = margin\n",
    "\t\tself.loss_tracker = metrics.Mean(name='loss')\n",
    "\n",
    "\tdef call(self, inputs):\n",
    "\t\treturn self.siamese_network(inputs)\n",
    "\n",
    "\tdef train_step(self, data):\n",
    "\t\t# GradientTape is a context manager that records every operation that\n",
    "\t\t# you do inside. We are using it here to compute the loss so we can get\n",
    "\t\t# the gradients and apply them using the optimizer specified in\n",
    "\t\t# `compile()`.\n",
    "\t\twith tf.GradientTape() as tape:\n",
    "\t\t\tloss = self._compute_loss(data)\n",
    "\t\t# Storing the gradients of the loss function with respect to the\n",
    "\t\t# weights/parameters.\n",
    "\t\tgradients = tape.gradient(loss, self.siamese_network.trainable_weights)\n",
    "\t\t# Applying the gradients on the model using the specified optimizer\n",
    "\t\tself.optimizer.apply_gradients(\n",
    "\t\t\tzip(gradients, self.siamese_network.trainable_weights)\n",
    "\t\t)\n",
    "\t\t# Let's update and return the training loss metric.\n",
    "\t\tself.loss_tracker.update_state(loss)\n",
    "\t\treturn {'loss': self.loss_tracker.result()}\n",
    "\n",
    "\tdef test_step(self, data):\n",
    "\t\tloss = self._compute_loss(data)\n",
    "\t\t# Let's update and return the loss metric.\n",
    "\t\tself.loss_tracker.update_state(loss)\n",
    "\t\treturn {'loss': self.loss_tracker.result()}\n",
    "\n",
    "\tdef _compute_loss(self, data):\n",
    "\t\t# The output of the network is a tuple containing the distances\n",
    "\t\t# between the anchor and the positive example, and the anchor and\n",
    "\t\t# the negative example.\n",
    "\t\tap_distance, an_distance = self.siamese_network(data)\n",
    "\t\t# Computing the Triplet Loss by subtracting both distances and\n",
    "\t\t# making sure we don't get a negative value.\n",
    "\t\tloss = ap_distance - an_distance\n",
    "\t\tloss = tf.maximum(loss + self.margin, 0.0)\n",
    "\t\treturn loss\n",
    "\n",
    "\t@property\n",
    "\tdef metrics(self):\n",
    "\t\t# We need to list our metrics here so the `reset_states()` can be\n",
    "\t\t# called automatically.\n",
    "\t\treturn [self.loss_tracker]\n",
    "\n",
    "\n",
    "def resize_images():\n",
    "\tfor filename in os.listdir('../food/'):\n",
    "\t\ttry:\n",
    "\t\t\timg = Image.open('../food/' + filename)\n",
    "\t\t\timg = img.resize(target_shape)\n",
    "\t\t\timg.save('../food_224/' + filename)\n",
    "\t\texcept Exception:\n",
    "\t\t\tpass\n",
    "\t\t\n",
    "\n",
    "def preprocess_image(filename):\n",
    "\timage_string = tf.io.read_file(filename)\n",
    "\timage = tf.image.decode_jpeg(image_string, channels=3)\n",
    "\timage = tf.image.convert_image_dtype(image, tf.float32)\n",
    "\timage = tf.image.resize(image, target_shape)\n",
    "\treturn image\n",
    "\n",
    "\n",
    "def preprocess_triplets(anchor, positive, negative):\n",
    "\treturn (\n",
    "\t\tpreprocess_image(anchor),\n",
    "\t\tpreprocess_image(positive),\n",
    "\t\tpreprocess_image(negative)\n",
    "\t)\n",
    "\n",
    "\n",
    "def preprocess_triplets_test(anchor, positive, negative):\n",
    "\treturn (\n",
    "\t\tpreprocess_image(anchor),\n",
    "\t\tpreprocess_image(positive),\n",
    "\t\tpreprocess_image(negative)\n",
    "\t), 1\n",
    "\n",
    "\n",
    "def get_datasets() -> tuple[int, TensorSliceDataset, TensorSliceDataset, TensorSliceDataset]:\n",
    "\tanchor_images = []\n",
    "\tpositive_images = []\n",
    "\tnegative_images = []\n",
    "\tfor index in range(len(train_triplet_lines)):\n",
    "\t\ttemp = train_triplet_lines[index].strip().split(' ')\n",
    "\t\tanchor_images.append(images_dir + temp[0] + '.jpg')\n",
    "\t\tif train_triplet_lines[index].strip() == '1':\n",
    "\t\t\tpositive_images.append(images_dir + temp[1] + '.jpg')\n",
    "\t\t\tnegative_images.append(images_dir + temp[2] + '.jpg')\n",
    "\t\telse:\n",
    "\t\t\tnegative_images.append(images_dir + temp[2] + '.jpg')\n",
    "\t\t\tpositive_images.append(images_dir + temp[1] + '.jpg')\n",
    "\treturn (\n",
    "\t\ttf.data.Dataset.from_tensor_slices(anchor_images),\n",
    "\t\ttf.data.Dataset.from_tensor_slices(positive_images),\n",
    "\t\ttf.data.Dataset.from_tensor_slices(negative_images),\n",
    "\t)\n",
    "\n",
    "\n",
    "def get_train_val():\n",
    "\tanchor_dataset, positive_dataset, negative_dataset = get_datasets()\n",
    "\n",
    "\tdataset = tf.data.Dataset.zip((anchor_dataset, positive_dataset, negative_dataset))\n",
    "\tdataset = dataset.shuffle(buffer_size=1024)\n",
    "\tdataset = dataset.map(preprocess_triplets)\n",
    "\ttrain_dataset = dataset.take(round(len(dataset) * 0.8))\n",
    "\tval_dataset = dataset.skip(round(len(dataset) * 0.8))\n",
    "\n",
    "\ttrain_dataset = train_dataset.batch(BATCH_SIZE, drop_remainder=False)\n",
    "\ttrain_dataset = train_dataset.prefetch(8)\n",
    "\n",
    "\tval_dataset = val_dataset.batch(BATCH_SIZE, drop_remainder=False)\n",
    "\tval_dataset = val_dataset.prefetch(8)\n",
    "\treturn (train_dataset, val_dataset)\n",
    "\n",
    "\n",
    "def get_datasets_test() -> tuple[int, TensorSliceDataset, TensorSliceDataset, TensorSliceDataset]:\n",
    "\tanchor_images = []\n",
    "\tpositive_images = []\n",
    "\tnegative_images = []\n",
    "\tfor index in range(len(test_triplet_lines)):\n",
    "\t\ttemp = test_triplet_lines[index].strip().split(' ')\n",
    "\t\tanchor_images.append(images_dir + temp[0] + '.jpg')\n",
    "\t\tif test_triplet_lines[index].strip() == '1':\n",
    "\t\t\tpositive_images.append(images_dir + temp[1] + '.jpg')\n",
    "\t\t\tnegative_images.append(images_dir + temp[2] + '.jpg')\n",
    "\t\telse:\n",
    "\t\t\tnegative_images.append(images_dir + temp[2] + '.jpg')\n",
    "\t\t\tpositive_images.append(images_dir + temp[1] + '.jpg')\n",
    "\tdataset = tf.data.Dataset.zip((\n",
    "\t\ttf.data.Dataset.from_tensor_slices(anchor_images),\n",
    "\t\ttf.data.Dataset.from_tensor_slices(positive_images),\n",
    "\t\ttf.data.Dataset.from_tensor_slices(negative_images)\n",
    "\t))\n",
    "\tdataset = dataset.map(preprocess_triplets_test)\n",
    "\tdataset = dataset.batch(BATCH_SIZE, drop_remainder=False)\n",
    "\tdataset = dataset.prefetch(8)\n",
    "\treturn dataset\n",
    "\n",
    "\n",
    "def get_datasets_test_test() -> tuple[int, TensorSliceDataset, TensorSliceDataset, TensorSliceDataset]:\n",
    "\tanchor_images = []\n",
    "\tfor filename in os.listdir(images_dir):\n",
    "\t\tanchor_images.append(images_dir + filename)\n",
    "\tdataset = tf.data.Dataset.from_tensor_slices(anchor_images)\n",
    "\tdataset = dataset.map(preprocess_image)\n",
    "\tdataset = dataset.batch(BATCH_SIZE, drop_remainder=False)\n",
    "\tdataset = dataset.prefetch(8)\n",
    "\treturn dataset\n",
    "\n",
    "\n",
    "def build_model() -> tuple[Model, SiameseModel]:\n",
    "\tembedding = tf.keras.Sequential()\n",
    "\tembedding.add(\n",
    "\t\thub.KerasLayer(\n",
    "\t\t'https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet1k_b0/feature_vector/2',\n",
    "\t\tinput_shape=target_shape + (3,),\n",
    "\t\ttrainable=True)\n",
    "\t)\n",
    "\tembedding.add(layers.Dropout(0.7))\n",
    "\tembedding.add(layers.Dense(4096, activation='relu'))\n",
    "\tembedding.add(layers.Dense(4096, activation='relu'))\n",
    "\tembedding.add(layers.Lambda(lambda  x: tf.keras.backend.l2_normalize(x, axis=1)))\n",
    "\n",
    "\tanchor_input = layers.Input(name='anchor', shape=target_shape + (3,))\n",
    "\tpositive_input = layers.Input(name='positive', shape=target_shape + (3,))\n",
    "\tnegative_input = layers.Input(name='negative', shape=target_shape + (3,))\n",
    "\n",
    "\tdistances = DistanceLayer()(\n",
    "\t\tembedding(efficientnet_v2.preprocess_input(anchor_input)),\n",
    "\t\tembedding(efficientnet_v2.preprocess_input(positive_input)),\n",
    "\t\tembedding(efficientnet_v2.preprocess_input(negative_input)),\n",
    "\t)\n",
    "\n",
    "\tsiamese_network = Model(\n",
    "\t\t\tinputs=[anchor_input, positive_input, negative_input], outputs=distances\n",
    "\t)\n",
    "\tsiamese_model = SiameseModel(siamese_network)\n",
    "\tsiamese_model.compile(optimizer=tf.keras.optimizers.Adam(0.00001))\n",
    "\treturn siamese_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset = get_train_val()\n",
    "test_dataset = get_datasets_test()\n",
    "siamese_model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_model.fit(train_dataset, epochs=6, validation_data=val_dataset)\n",
    "# siamese_model.save_weights('./weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# siamese_model.load_weights('./weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = siamese_model.predict(\n",
    "\ttest_dataset,\n",
    "\tverbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = pred[0]\n",
    "neg = pred[1]\n",
    "result = open('result.txt', 'w')\n",
    "for index in range(len(pos)):\n",
    "\tresult.write('{}\\n'.format(1 if pos[index] < neg[index] else 0))\n",
    "result.close()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "81a15479a237f7953c7618720d7a7ff36a3ba4a5579d9537e630d96f217658ef"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
